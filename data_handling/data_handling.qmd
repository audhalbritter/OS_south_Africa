---
title: "Data handling and curation - from raw to clean data"
author: "Aud Halbritter (adapted from Matt Grainger)"
format: 
  revealjs:
    embed-resources: true
    theme: moon
    slide-number: true
    show-slide-number: all
    
execute:
  echo: true
editor: visual
---

```{r}

#| label: setup
#| echo: false
#| eval: true
#| message: false

library(tidyverse) 
library(palmerpenguins) 
library(janitor) 
library(knitr)

```

## {}

![](pics/Ecology_data.jfif)

## Data cycle

![](pics/Screenshot 2024-10-15 at 09.31.32.png)

## Data handling and curation is time consuming

![](pics/time_spent.png){width=300}

## Data cleaning vs Data wrangling

***Data cleaning*** is the process of removing incorrect, duplicate, typos, or otherwise erroneous data from a dataset

***Data wrangling*** changing the format to make it more useful for your analysis


## 

### Data cleaning with the Palmer penguins dataset

![](pics/lter_penguins.png){width=120}


::: callout-note
### Exercise
Run the following commands.
:::

```{r}
#| label: palmer-pemguins
#| echo: true
#| eval: true
#| message: false

#install.packages("palmerpenguins")
library(palmerpenguins)
head(penguins)

```

## 

### Clean names with janitor

```{r}
#| label: janitor
#| echo: true
#| eval: true

penguins |> 
  names() 

```

```{r}
#| label: janitor2
#| echo: true
#| eval: true

penguins_clean <- penguins |> 
  janitor::clean_names(case = "snake") 

penguins_clean |> 
  names()

```

## 

### Get a glimps wiht dplyr


```{r}
#| label: glimpse
#| echo: true
#| eval: true

penguins_clean |>
  dplyr::glimpse()

```

##

### Skim your data with skimr

```{r}
#| label: skimr
#| echo: true
#| eval: true
#| 
out <- penguins_clean |> 
  skimr::skim() 

out

```


## Data cleaning

- Do not touch raw data files
- Clean data with code
- Check each cleaning step


## 

### Keep track of changes with tidylog

![](pics/tidylog.png)


##

### Remove duplicates with dplyr

```{r}
#| label: duplicates1
#| echo: false
#| eval: true
#| 
duplicate_data <- tibble(Day = c("Monday", "Tuesday","Wednesday", "Wednesday"), 
               Person = c("Becks", "Amy", "Matt", "Matt"))

```

```{r}
#| label: duplicates2
#| echo: false
#| eval: true
#| 

duplicate_data

```

```{r}
#| label: duplicates3
#| echo: true
#| eval: true

duplicate_data |> 
  dplyr::distinct()

```


## Missing data

Missing data is often a problem, e.g. for running a model. Typically as ecologists we sweep missing data under the carpet by using a "complete case" approach to data analysis.

![](pics/SWEEP-IT-UNDER-THE-CARPET-BANKSY-2.jpg)


## 

If you have ever written some code like this:

```{r}
#| label: remove-nas
#| echo: true
#| eval: false

newdf <- na.omit(penguins_clean)

newdf <- penguins_clean[complete.cases(penguins_clean), ]

newdf <- penguins_clean |>
  tidyr::drop_na()

```

you are removing missing data (NAs) from your dataset.

## 

### Why is this a problem?

By throwing away potentially useful data (only including those rows without a NA in them) you reduce the information you are working with, reduce statistical power and introduce selection bias (invalidating any assumption of randomisation).


## 

### Vizualise missing data with naniar

```{r}
#| label: naniar
#| echo: true
#| eval: true

penguins_clean |> 
  naniar::vis_miss()
```


## 

### Different types of missingness

Data can be missing random or systematically. Random missing data is less problematic.

```{r}
#| label: naniar-viz
#| echo: true
#| eval: true

library(naniar)
penguins_clean |> 
  ggplot(aes(x = bill_length_mm, y = body_mass_g)) +
  geom_miss_point()

```


## 

### Data validation

```{r}
#| label: validation
#| echo: true
#| eval: true
#| messages: false

library(validate)

rules <- validator(bill_length_mm >= 0, 
                   body_mass_g > 3000,
                   is.character(species),
                   sex %in% c("female", "male"))

```


## 

### Data validation

```{r}
#| label: validation-summary
#| echo: true
#| eval: true
#| messages: false

out   <- confront(penguins_clean, rules)
summary(out)

```

## 

### Data validation

```{r}
#| label: validation-plot
#| echo: true
#| eval: true
#| messages: false

plot(out)

```

## 

### Data wrangling with dplyr

![](pics/Dplyr_1.jpg)

## 

### Data wrangling with dplyr

![](pics/Dplyr_2.jpg)

##

### Data wrangling with tidyr

![](pics/Dplyr_3.jpg)


## Code style

["Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread."](https://style.tidyverse.org/)

```{r}
#| label: style-guide
#| echo: true
#| eval: false


my_function <- function(my_data){
  
  my_data |> 
    group_by(group) |> 
    summarise(mean = mean(variable),
              se = sd(variable)/sqrt(n()))
  
} 

my_function<-function(my_data){
  my_data|> group_by(group)|> 
    summarise(mean=mean(variable),se=sd(variable)/sqrt(n()))} 

```


## Useful package for style

```{r}
#| label: styler
#| echo: true
#| eval: false

library(styler)
 
style_text("my_function<-function(my_data){
  my_data|> group_by(group)|> 
    summarise(mean=mean(variable),se=sd(variable)/sqrt(n()))}")  

```

## Useful package for style

![](pics/styler.png)


## 

::: callout-note
### Exercise
Use the raw penguine data and do the following tasks.

- clean the names
:::


