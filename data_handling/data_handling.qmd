---
title: "Data handling and curation - from raw to clean data"
author: "Aud Halbritter (adapted from Matt Grainger)"
format: 
  revealjs:
    embed-resources: true
    theme: moon
    slide-number: true
    show-slide-number: all
    
editor: visual
---

```{r}

#| label: setup
#| echo: false
#| eval: true

library(tidyverse) 
library(palmerpenguins) 
library(janitor) 
library(knitr)

```

## {}

![](pics/Ecology_data.jfif)

## Data cycle

![](pics/data_cycle.png)

## Data handling and curation is time consuming

![](pics/time_spent.png){width=300}

## Data cleaning vs Data wrangling

***Data cleaning*** is the process of removing incorrect, duplicate, typos, or otherwise erroneous data from a dataset

***Data wrangling*** changing the format to make it more useful for your analysis


## 

### Import data with read_delim

See [Import data](https://biostats-r.github.io/biostats/workingInR/005_Importing_Data_in_R.html) BioST@TS tutorial

```{r}
#| label: import
#| echo: true
#| eval: false

read_delim(file = "data/plant_community_2024.csv")

```



## 

### Data cleaning with the Palmer penguins dataset

![](pics/lter_penguins.png){width=120}

## 

::: callout-note
### Exercise
Run the following commands to install the palmerpenguins package.
:::

```{r}
#| label: palmer-pemguins
#| echo: true
#| eval: true
#| message: false

#install.packages("palmerpenguins")
library(palmerpenguins)
head(penguins_raw)

```


## 

### Clean names with janitor

```{r}
#| label: janitor
#| echo: true
#| eval: true

penguins_raw |> 
  names() 

```

## 

### Clean names with janitor

```{r}
#| label: janitor2
#| echo: true
#| eval: true

penguins_raw |> 
  names() 

```

```{r}
#| label: janitor3
#| echo: true
#| eval: true

penguins_clean <- penguins_raw |> 
  janitor::clean_names(case = "snake") 

penguins_clean |> 
  names()

```

## 

### Get a glimps wiht dplyr


```{r}
#| label: glimpse
#| echo: true
#| eval: true

penguins_clean |>
  dplyr::glimpse()

```

##

### Skim your data with skimr

```{r}
#| label: skimr
#| echo: true
#| eval: true
#| 
out <- penguins_clean |> 
  skimr::skim() 

out

```


## 

::: callout-note
### Exercise
Run the following functions:

`clean_names()`

`glimpse()`

`skimr::skim()`
:::


## 

### Data validation

```{r}
#| label: validation
#| echo: true
#| eval: true
#| messages: false

library(validate)

rules <- validator(culm = culmen_length_mm >= 0, 
                   body = body_mass_g > 3000,
                   species = is.character(species),
                   sex = sex %in% c("FEMALES", "MALE"))

```


## 

### Data validation

```{r}
#| label: validation-summary
#| echo: true
#| eval: true
#| messages: false

out   <- confront(penguins_clean, rules)
summary(out)

```

## 

### Data validation

```{r}
#| label: validation-plot
#| echo: true
#| eval: true
#| messages: false

plot(out)

```


## Rules for data cleaning

- Deposit and back-up raw data files 
- Do not manually manipulate the raw data files
- Clean data using code
- Check the cleaning code


## 

### Keep track of changes with tidylog

```{r}
#| label: tidylog
#| echo: true
#| eval: true
#| message: false

library(tidylog)

```

```{r}
#| label: tidylog2
#| echo: true
#| eval: true
#| message: true

dat <- penguins_clean |> 
  tidylog::select(study_name, species, island, individual_id, body_mass_g) |> 
  tidylog::filter(species %in% c("Adelie Penguin (Pygoscelis adeliae)"))

```



##

### Remove duplicates with dplyr

```{r}
#| label: duplicates1
#| echo: false
#| eval: true

duplicate_data <- tibble(Day = c("Monday", "Tuesday","Wednesday", "Wednesday"), 
               Person = c("Becks", "Amy", "Matt", "Matt"))

```

```{r}
#| label: duplicates2
#| echo: false
#| eval: true
#| 

duplicate_data

```

##

### Remove duplicates with dplyr

```{r}
#| label: duplicates3
#| echo: true
#| eval: true
#| message: true

duplicate_data |> 
  tidylog::distinct()

```


## Missing data

Missing data is often a problem, e.g. for running a model. Typically as ecologists we sweep missing data under the carpet by using a "complete case" approach to data analysis.

![](pics/SWEEP-IT-UNDER-THE-CARPET-BANKSY-2.jpg)


## 

If you have ever written some code like this:

```{r}
#| label: remove-nas
#| echo: true
#| eval: false

newdf <- na.omit(penguins_clean)

newdf <- penguins_clean[complete.cases(penguins_clean), ]

newdf <- penguins_clean |>
  tidyr::drop_na()

```

you are removing missing data (NAs) from your dataset.

## 

### Why is this a problem?

By throwing away potentially useful data (only including those rows without a NA in them) you reduce the information you are working with, reduce statistical power and introduce selection bias (invalidating any assumption of randomisation).


## 

### Vizualise missing data with naniar

```{r}
#| label: make-messy
#| echo: false
#| eval: true

library(messy)
set.seed(1234)
penguins_messy <- bind_cols(penguins |> 
                              select(year, species, island, sex, body_mass_g), 
                            messy(penguins[3:4])) |> 
  mutate(bill_length_mm = as.numeric(bill_length_mm),
         bill_depth_mm = as.numeric(bill_depth_mm))

```


```{r}
#| label: naniar
#| echo: true
#| eval: true

penguins_messy |> 
  naniar::vis_miss()
```


## 

### Different types of missingness

Data can be missing random or systematically.

```{r}
#| label: naniar-viz
#| echo: true
#| eval: true

library(naniar)
penguins_messy |> 
  ggplot(aes(x = bill_length_mm, y = body_mass_g)) +
  geom_miss_point()

```




## 

### Data wrangling with dplyr

![](pics/Dplyr_1.jpg)

## 

### Data wrangling with dplyr

![](pics/Dplyr_2.jpg)

##

### Data wrangling with tidyr

![](pics/Dplyr_3.jpg)

## 

::: callout-note
### Exercise
Use the penguins dataset to:

- Select the columns species, island and body_mass_g
- Filter for the species Adelie and the island Biscoe and Dream

- Convert the penguin body mass from gram to kilogram
- Calculate the mean bill length and standard error for each penguin species
- Make a wide dataset showing the body mass for each penguin species in a separate column. And turn it back to a long dataframe.

Import the *messy_data.RDS* data file and clean it.

:::


## Reproducible workflows

![](pics/non-rep.png)

## Reproducible workflows

![](pics/quarto_workflow2.png)


